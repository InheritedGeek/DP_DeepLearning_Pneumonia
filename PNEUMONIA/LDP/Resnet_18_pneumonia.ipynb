{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Resnet_18_pneumonia.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxejS4BhtfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4b9cd4fd-43fa-4c26-9a27-fc8c4ddc9268"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 12 03:33:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqzKNkpfXrM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bba57d72-3c36-40c9-c921-5234aab98816"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tkHSteTnOUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import numpy as np \n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "import copy\n",
        "from tqdm import tqdm as tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "best_model = None\n",
        "best_loss = 0.\n",
        "best_test_loss = 0.\n",
        "best_test_acc = 0.\n",
        "best_pred_labels = []\n",
        "true_labels = []\n",
        "\n",
        "pred_labels = []\n",
        "test_acc = 0.\n",
        "test_loss = 0.\n",
        "\n",
        "# device = torch.device('cuda:0')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjX3GQUHnOUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3f05c7ee-62e5-4dec-9e13-db94505b85df"
      },
      "source": [
        "# train class samples from Non DP data\n",
        "print('Normal Samples in Training Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/train/NORMAL | wc -l\n",
        "print('Pneumonia Samples in Training Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/train/PNEUMONIA | wc -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Samples in Training Data\n",
            "1342\n",
            "Pneumonia Samples in Training Data\n",
            "3876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOR0OlpIbDFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e64fda6e-04f3-4efd-a534-b731e1020783"
      },
      "source": [
        "# Validation samples from Non DP data\n",
        "print('Normal Samples in Validation Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/val/NORMAL | wc -l\n",
        "print('Pneumonia Samples in Validation Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/val/PNEUMONIA | wc -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Samples in Validation Data\n",
            "9\n",
            "Pneumonia Samples in Validation Data\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8YxWrN7nOUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7d7f5e9f-610d-4ca2-b659-e693494080c2"
      },
      "source": [
        "# Testing samples from Non DP data\n",
        "print('Normal Samples in Testing Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/test/NORMAL | wc -l\n",
        "print('Pneumonia Samples in Testing Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/test/PNEUMONIA | wc -l"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Samples in Testing Data\n",
            "235\n",
            "Pneumonia Samples in Testing Data\n",
            "391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiuaHzKIFjYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copying to local to process/train faster\n",
        "\n",
        "!cp -R /content/drive/\"My Drive\"/NDP_Data/chest_xray/train ./\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GZsr5LpFtXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copying to local to process/run faster during validation inference\n",
        "\n",
        "!cp -R /content/drive/\"My Drive\"/NDP_Data/chest_xray/val ./\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh3E7LaXFukl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copying to local to process/run faster during testing inference\n",
        "\n",
        "!cp -R /content/drive/\"My Drive\"/NDP_Data/chest_xray/test ./"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfTrqSj1JSCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "458bd745-bbe8-4726-a6d1-4050d7b64cf6"
      },
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Jun 26 16:26 sample_data\n",
            "drwx------ 4 root root 4096 Jul 12 03:33 drive\n",
            "drwx------ 4 root root 4096 Jul 12 03:37 train\n",
            "drwx------ 4 root root 4096 Jul 12 03:47 val\n",
            "drwx------ 4 root root 4096 Jul 12 03:49 test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPDTSXKWnOUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ChestXRay(torchvision.datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        sample, target = super().__getitem__(index)\n",
        "        path, _ = self.samples[index]\n",
        "        \n",
        "        target = 0\n",
        "        if 'PNEUMONIA' in path:\n",
        "            target = 1\n",
        "        \n",
        "        return sample, target\n",
        "       "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-_xESJtnOU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.RandomAffine(0, translate=(0, 0.1), scale=(1, 1.10)),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "#train_dataset = ChestXRay('/content/drive/My Drive/NDP_Data/chest_xray/train/', transform=train_transforms)\n",
        "#val_dataset = ChestXRay('/content/drive/My Drive/NDP_Data/chest_xray/val/', transform=train_transforms)\n",
        "#test_dataset = ChestXRay('/content/drive/My Drive/NDP_Data/chest_xray/test/', transform=transforms)\n",
        "\n",
        "train_dataset = ChestXRay('./train/', transform=train_transforms)\n",
        "val_dataset = ChestXRay('./val/', transform=train_transforms)\n",
        "test_dataset = ChestXRay('./test/', transform=transforms)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee19YDP1nOVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "261bb1fb-c322-43b2-d9f9-7d0a92788070"
      },
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = torch.nn.Linear(in_features=512, out_features=2)\n",
        "model = model.to(device)\n",
        "model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61IVJvrmr7th",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f72ca15-f445-407a-b16b-a273b195d0c7"
      },
      "source": [
        "summary(model.cuda(), [(3,224,224,)])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 11,177,538\n",
            "Trainable params: 11,177,538\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhXhlzFK2Dl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5U-QpQHr7wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAoD68pMf5oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epoch(model, dataloader, criterion, optimizer, lr_scheduler, phase='train'):\n",
        "    epoch_loss = 0.\n",
        "    epoch_acc = 0.\n",
        "    \n",
        "    batch_num = 0.\n",
        "    samples_num = 0.\n",
        "    \n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    \n",
        "    for batch_idx, (data, labels) in enumerate(dataloader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "            outputs = model(data)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "        \n",
        "        true_labels.append(labels.detach().cpu())\n",
        "        pred_labels.append(preds.detach().cpu())\n",
        "        \n",
        "        if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        print(f'\\r{phase} batch [{batch_idx}/{len(dataloader)}]: loss {loss.item()}', end='', flush=True)\n",
        "        epoch_loss += loss.detach().cpu().item()\n",
        "        epoch_acc += torch.sum(preds == labels.data)\n",
        "        batch_num += 1\n",
        "        samples_num += len(labels)\n",
        "    \n",
        "    print()\n",
        "    return epoch_loss / batch_num, epoch_acc / samples_num, torch.cat(true_labels).numpy(), torch.cat(pred_labels).numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68w_Ljsff9wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7qXbQPUgRnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCUrp4S-gRqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=0.001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAn4FWp3nOVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "712fd61b-9e1f-451a-da54-b8acd8ef4dcf"
      },
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "test_losses = []\n",
        "output_folder = '/content/drive/My Drive/Dataset/a/'\n",
        "for epoch in range(50):\n",
        "    print('='*15, f'Epoch: {epoch}')\n",
        "    \n",
        "    train_loss, train_acc, _, _ = run_epoch(model, train_dataloader, criterion, optimizer, lr_scheduler)\n",
        "    val_loss, val_acc, _, _ = run_epoch(model, val_dataloader, criterion, optimizer, lr_scheduler, phase='val')\n",
        "    test_loss, test_acc, true_labels, pred_labels = run_epoch(model, test_dataloader, criterion, optimizer, lr_scheduler, phase='test')\n",
        "    \n",
        "    print(f'Train loss: {train_loss}, Train accuracy: {train_acc}')\n",
        "    print(f'Val loss: {val_loss}, Val accuracy: {val_acc}')\n",
        "    print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n",
        "    print()\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    \n",
        "    np.save(output_folder+'/train_losses',train_losses)\n",
        "    np.save(output_folder+'/val_losses',val_losses)\n",
        "    np.save(output_folder+'/test_losses',test_losses)\n",
        "    \n",
        "    torch.save({'epoch': epoch, 'model': model.state_dict()}, f'resnet34-chest-x-ray-{seed}.pt')\n",
        "    \n",
        "    if best_model is None or val_loss < best_loss:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_loss = val_loss\n",
        "        best_test_loss = test_loss\n",
        "        best_test_acc = test_acc \n",
        "        best_pred_labels = pred_labels\n",
        "        torch.save({'epoch': epoch, 'model': model.state_dict()}, f'resnet34-chest-x-ray_ldp-best-{seed}.pt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=============== Epoch: 0\n",
            "train batch [40/41]: loss 0.17394894361495972\n",
            "val batch [3/4]: loss 0.17651067674160004\n",
            "test batch [4/5]: loss 0.30307313799858093\n",
            "Train loss: 0.22482654452323914, Train accuracy: 0.91679447889328\n",
            "Val loss: 1.1857282519340515, Val accuracy: 0.5\n",
            "Test loss: 0.9913603365421295, Test accuracy: 0.6282051205635071\n",
            "\n",
            "=============== Epoch: 1\n",
            "train batch [40/41]: loss 0.1388559341430664\n",
            "val batch [3/4]: loss 0.15031611919403076\n",
            "test batch [4/5]: loss 0.2741760313510895\n",
            "Train loss: 0.11070913040056461, Train accuracy: 0.9614647030830383\n",
            "Val loss: 1.3944829180836678, Val accuracy: 0.5625\n",
            "Test loss: 1.1378524422645568, Test accuracy: 0.629807710647583\n",
            "\n",
            "=============== Epoch: 2\n",
            "train batch [40/41]: loss 0.06409323215484619\n",
            "val batch [3/4]: loss 0.06272467970848083\n",
            "test batch [4/5]: loss 0.20815742015838623\n",
            "Train loss: 0.08466026904742892, Train accuracy: 0.9699003100395203\n",
            "Val loss: 1.66521055996418, Val accuracy: 0.5625\n",
            "Test loss: 1.3093023300170898, Test accuracy: 0.6442307829856873\n",
            "\n",
            "=============== Epoch: 3\n",
            "train batch [40/41]: loss 0.04537128284573555\n",
            "val batch [3/4]: loss 0.11470435559749603\n",
            "test batch [4/5]: loss 0.24904076755046844\n",
            "Train loss: 0.07193305007204777, Train accuracy: 0.9737346172332764\n",
            "Val loss: 1.6946359239518642, Val accuracy: 0.5\n",
            "Test loss: 1.295104244351387, Test accuracy: 0.6362179517745972\n",
            "\n",
            "=============== Epoch: 4\n",
            "train batch [40/41]: loss 0.09458118677139282\n",
            "val batch [3/4]: loss 0.10763430595397949\n",
            "test batch [4/5]: loss 0.35304421186447144\n",
            "Train loss: 0.062444328625754615, Train accuracy: 0.9791027307510376\n",
            "Val loss: 1.7452089041471481, Val accuracy: 0.5\n",
            "Test loss: 1.2852482736110686, Test accuracy: 0.6217948794364929\n",
            "\n",
            "=============== Epoch: 5\n",
            "train batch [40/41]: loss 0.02941664308309555\n",
            "val batch [3/4]: loss 0.06656487286090851\n",
            "test batch [4/5]: loss 0.21504473686218262\n",
            "Train loss: 0.05430457050480494, Train accuracy: 0.9804447889328003\n",
            "Val loss: 2.033775318413973, Val accuracy: 0.5\n",
            "Test loss: 1.4175214648246766, Test accuracy: 0.6458333134651184\n",
            "\n",
            "=============== Epoch: 6\n",
            "train batch [40/41]: loss 0.08937080949544907\n",
            "val batch [3/4]: loss 0.1650470346212387\n",
            "test batch [4/5]: loss 0.26074162125587463\n",
            "Train loss: 0.04682936224086982, Train accuracy: 0.9833205342292786\n",
            "Val loss: 2.0404686480760574, Val accuracy: 0.5625\n",
            "Test loss: 1.430411148071289, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 7\n",
            "train batch [40/41]: loss 0.06797466427087784\n",
            "val batch [3/4]: loss 0.07404376566410065\n",
            "test batch [4/5]: loss 0.20304451882839203\n",
            "Train loss: 0.04137554680701436, Train accuracy: 0.9854294061660767\n",
            "Val loss: 2.006323877722025, Val accuracy: 0.5\n",
            "Test loss: 1.556475540995598, Test accuracy: 0.6426281929016113\n",
            "\n",
            "=============== Epoch: 8\n",
            "train batch [40/41]: loss 0.021700432524085045\n",
            "val batch [3/4]: loss 0.05455085635185242\n",
            "test batch [4/5]: loss 0.21750102937221527\n",
            "Train loss: 0.03716255104305541, Train accuracy: 0.9873465895652771\n",
            "Val loss: 2.0823179706931114, Val accuracy: 0.5625\n",
            "Test loss: 1.5696318417787551, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 9\n",
            "train batch [40/41]: loss 0.05553906038403511\n",
            "val batch [3/4]: loss 0.06198936700820923\n",
            "test batch [4/5]: loss 0.30699944496154785\n",
            "Train loss: 0.03515466770566091, Train accuracy: 0.9904140830039978\n",
            "Val loss: 2.0240380838513374, Val accuracy: 0.5625\n",
            "Test loss: 1.5366359412670136, Test accuracy: 0.6314102411270142\n",
            "\n",
            "=============== Epoch: 10\n",
            "train batch [40/41]: loss 0.07532939314842224\n",
            "val batch [3/4]: loss 0.04012134671211243\n",
            "test batch [4/5]: loss 0.2729165852069855\n",
            "Train loss: 0.030479841683877677, Train accuracy: 0.9888803362846375\n",
            "Val loss: 2.065629679709673, Val accuracy: 0.5625\n",
            "Test loss: 1.6064594388008118, Test accuracy: 0.634615421295166\n",
            "\n",
            "=============== Epoch: 11\n",
            "train batch [40/41]: loss 0.021875647827982903\n",
            "val batch [3/4]: loss 0.025784283876419067\n",
            "test batch [4/5]: loss 0.2861565053462982\n",
            "Train loss: 0.026292942078193514, Train accuracy: 0.9917561411857605\n",
            "Val loss: 2.121567890048027, Val accuracy: 0.5625\n",
            "Test loss: 1.646896868944168, Test accuracy: 0.6282051205635071\n",
            "\n",
            "=============== Epoch: 12\n",
            "train batch [40/41]: loss 0.03162276744842529\n",
            "val batch [3/4]: loss 0.09723140299320221\n",
            "test batch [4/5]: loss 0.338235467672348\n",
            "Train loss: 0.02655924861205787, Train accuracy: 0.9909892678260803\n",
            "Val loss: 2.018524434417486, Val accuracy: 0.5\n",
            "Test loss: 1.6114954829216004, Test accuracy: 0.6330128312110901\n",
            "\n",
            "=============== Epoch: 13\n",
            "train batch [40/41]: loss 0.037385012954473495\n",
            "val batch [3/4]: loss 0.06817516684532166\n",
            "test batch [4/5]: loss 0.2442673295736313\n",
            "Train loss: 0.024948383851840002, Train accuracy: 0.9915643930435181\n",
            "Val loss: 2.2183528505265713, Val accuracy: 0.5625\n",
            "Test loss: 1.7015038818120956, Test accuracy: 0.6474359035491943\n",
            "\n",
            "=============== Epoch: 14\n",
            "train batch [40/41]: loss 0.021527787670493126\n",
            "val batch [3/4]: loss 0.034704238176345825\n",
            "test batch [4/5]: loss 0.3155481517314911\n",
            "Train loss: 0.02337871213648014, Train accuracy: 0.9913727045059204\n",
            "Val loss: 2.151687577366829, Val accuracy: 0.5625\n",
            "Test loss: 1.7154198050498963, Test accuracy: 0.6282051205635071\n",
            "\n",
            "=============== Epoch: 15\n",
            "train batch [40/41]: loss 0.009952142834663391\n",
            "val batch [3/4]: loss 0.0186518132686615\n",
            "test batch [4/5]: loss 0.24233771860599518\n",
            "Train loss: 0.01666806214602619, Train accuracy: 0.9950153231620789\n",
            "Val loss: 2.3520941957831383, Val accuracy: 0.5625\n",
            "Test loss: 1.788803580403328, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 16\n",
            "train batch [40/41]: loss 0.022479556500911713\n",
            "val batch [3/4]: loss 0.0649167001247406\n",
            "test batch [4/5]: loss 0.30735236406326294\n",
            "Train loss: 0.0151122826174265, Train accuracy: 0.9969325065612793\n",
            "Val loss: 2.2491311244666576, Val accuracy: 0.5625\n",
            "Test loss: 1.7826186776161195, Test accuracy: 0.6282051205635071\n",
            "\n",
            "=============== Epoch: 17\n",
            "train batch [40/41]: loss 0.004326757043600082\n",
            "val batch [3/4]: loss 0.1202065721154213\n",
            "test batch [4/5]: loss 0.34168335795402527\n",
            "Train loss: 0.017004387759853426, Train accuracy: 0.9952070116996765\n",
            "Val loss: 2.2185627836734056, Val accuracy: 0.5625\n",
            "Test loss: 1.8103413522243499, Test accuracy: 0.629807710647583\n",
            "\n",
            "=============== Epoch: 18\n",
            "train batch [40/41]: loss 0.028385356068611145\n",
            "val batch [3/4]: loss 0.0140458345413208\n",
            "test batch [4/5]: loss 0.3122744560241699\n",
            "Train loss: 0.016862277395841552, Train accuracy: 0.9944401383399963\n",
            "Val loss: 2.313801631331444, Val accuracy: 0.5625\n",
            "Test loss: 1.8738834619522096, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 19\n",
            "train batch [40/41]: loss 0.009342141449451447\n",
            "val batch [3/4]: loss 0.05443698167800903\n",
            "test batch [4/5]: loss 0.2724718749523163\n",
            "Train loss: 0.013825309122117555, Train accuracy: 0.9969325065612793\n",
            "Val loss: 2.391921494156122, Val accuracy: 0.4375\n",
            "Test loss: 1.8807512879371644, Test accuracy: 0.6394230723381042\n",
            "\n",
            "=============== Epoch: 20\n",
            "train batch [40/41]: loss 0.003356851637363434\n",
            "val batch [3/4]: loss 0.0230657160282135\n",
            "test batch [4/5]: loss 0.3580983281135559\n",
            "Train loss: 0.01199936460158447, Train accuracy: 0.9973159432411194\n",
            "Val loss: 2.349440775811672, Val accuracy: 0.5625\n",
            "Test loss: 1.9242590367794037, Test accuracy: 0.6330128312110901\n",
            "\n",
            "=============== Epoch: 21\n",
            "train batch [40/41]: loss 0.010862454771995544\n",
            "val batch [3/4]: loss 0.017625659704208374\n",
            "test batch [4/5]: loss 0.3721170127391815\n",
            "Train loss: 0.011225555376036138, Train accuracy: 0.9963573217391968\n",
            "Val loss: 2.328797586262226, Val accuracy: 0.5625\n",
            "Test loss: 1.947302407026291, Test accuracy: 0.625\n",
            "\n",
            "=============== Epoch: 22\n",
            "train batch [40/41]: loss 0.036557551473379135\n",
            "val batch [3/4]: loss 0.07566623389720917\n",
            "test batch [4/5]: loss 0.3053843677043915\n",
            "Train loss: 0.012812511915931614, Train accuracy: 0.9961656332015991\n",
            "Val loss: 2.451198574155569, Val accuracy: 0.4375\n",
            "Test loss: 1.9288485586643218, Test accuracy: 0.6426281929016113\n",
            "\n",
            "=============== Epoch: 23\n",
            "train batch [40/41]: loss 0.011217688210308552\n",
            "val batch [3/4]: loss 0.04135456681251526\n",
            "test batch [4/5]: loss 0.3144814670085907\n",
            "Train loss: 0.011406321317048334, Train accuracy: 0.9969325065612793\n",
            "Val loss: 2.509791061282158, Val accuracy: 0.5625\n",
            "Test loss: 1.9529275000095367, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 24\n",
            "train batch [40/41]: loss 0.007683722767978907\n",
            "val batch [3/4]: loss 0.04881945252418518\n",
            "test batch [4/5]: loss 0.38081100583076477\n",
            "Train loss: 0.009710855361801095, Train accuracy: 0.997124195098877\n",
            "Val loss: 2.4405255056917667, Val accuracy: 0.5625\n",
            "Test loss: 1.980895072221756, Test accuracy: 0.634615421295166\n",
            "\n",
            "=============== Epoch: 25\n",
            "train batch [40/41]: loss 0.007259974721819162\n",
            "val batch [3/4]: loss 0.018266618251800537\n",
            "test batch [4/5]: loss 0.3372465968132019\n",
            "Train loss: 0.008796168758147737, Train accuracy: 0.9980828166007996\n",
            "Val loss: 2.4473316483199596, Val accuracy: 0.5625\n",
            "Test loss: 1.995069682598114, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 26\n",
            "train batch [40/41]: loss 0.011154788546264172\n",
            "val batch [3/4]: loss 0.020071864128112793\n",
            "test batch [4/5]: loss 0.33961063623428345\n",
            "Train loss: 0.006161340012601236, Train accuracy: 0.9990413784980774\n",
            "Val loss: 2.5971133336424828, Val accuracy: 0.5625\n",
            "Test loss: 2.0302285671234133, Test accuracy: 0.6362179517745972\n",
            "\n",
            "=============== Epoch: 27\n",
            "train batch [40/41]: loss 0.007830112241208553\n",
            "val batch [3/4]: loss 0.01750209927558899\n",
            "test batch [4/5]: loss 0.36226364970207214\n",
            "Train loss: 0.007133724576816327, Train accuracy: 0.9980828166007996\n",
            "Val loss: 2.592788852751255, Val accuracy: 0.5625\n",
            "Test loss: 2.078697609901428, Test accuracy: 0.6410256624221802\n",
            "\n",
            "=============== Epoch: 28\n",
            "train batch [40/41]: loss 0.0012597590684890747\n",
            "val batch [3/4]: loss 0.013827085494995117\n",
            "test batch [4/5]: loss 0.41390302777290344\n",
            "Train loss: 0.007855690447840749, Train accuracy: 0.9980828166007996\n",
            "Val loss: 2.524383269250393, Val accuracy: 0.5625\n",
            "Test loss: 2.1106878936290743, Test accuracy: 0.634615421295166\n",
            "\n",
            "=============== Epoch: 29\n",
            "train batch [40/41]: loss 0.001980271190404892\n",
            "val batch [3/4]: loss 0.04543498158454895\n",
            "test batch [4/5]: loss 0.41211429238319397\n",
            "Train loss: 0.00770936623533688, Train accuracy: 0.9980828166007996\n",
            "Val loss: 2.4145852103829384, Val accuracy: 0.5\n",
            "Test loss: 2.0707652270793915, Test accuracy: 0.629807710647583\n",
            "\n",
            "=============== Epoch: 30\n",
            "train batch [40/41]: loss 0.0042638350278139114\n",
            "val batch [3/4]: loss 0.09394313395023346\n",
            "test batch [4/5]: loss 0.3770723044872284\n",
            "Train loss: 0.007744755084830813, Train accuracy: 0.9982745051383972\n",
            "Val loss: 2.61417443677783, Val accuracy: 0.5625\n",
            "Test loss: 2.0835542142391206, Test accuracy: 0.6314102411270142\n",
            "\n",
            "=============== Epoch: 31\n",
            "train batch [40/41]: loss 0.008680721744894981\n",
            "val batch [3/4]: loss 0.019319891929626465\n",
            "test batch [4/5]: loss 0.35723549127578735\n",
            "Train loss: 0.006063215769600214, Train accuracy: 0.9988496899604797\n",
            "Val loss: 2.695303589105606, Val accuracy: 0.5\n",
            "Test loss: 2.1269349277019503, Test accuracy: 0.6394230723381042\n",
            "\n",
            "=============== Epoch: 32\n",
            "train batch [40/41]: loss 0.0008057703380472958\n",
            "val batch [3/4]: loss 0.012247920036315918\n",
            "test batch [4/5]: loss 0.3802441656589508\n",
            "Train loss: 0.0044887058121697385, Train accuracy: 0.9994248151779175\n",
            "Val loss: 2.626629516482353, Val accuracy: 0.5625\n",
            "Test loss: 2.1673262655735015, Test accuracy: 0.634615421295166\n",
            "\n",
            "=============== Epoch: 33\n",
            "train batch [40/41]: loss 0.0035165671724826097\n",
            "val batch [3/4]: loss 0.00953984260559082\n",
            "test batch [4/5]: loss 0.3966076076030731\n",
            "Train loss: 0.0049666064882242095, Train accuracy: 0.9990413784980774\n",
            "Val loss: 2.5772224217653275, Val accuracy: 0.5625\n",
            "Test loss: 2.1773909866809844, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 34\n",
            "train batch [40/41]: loss 0.0021943238098174334\n",
            "val batch [3/4]: loss 0.020552605390548706\n",
            "test batch [4/5]: loss 0.3597271740436554\n",
            "Train loss: 0.004277384266393577, Train accuracy: 0.9994248151779175\n",
            "Val loss: 2.8122699335217476, Val accuracy: 0.5\n",
            "Test loss: 2.174902480840683, Test accuracy: 0.6394230723381042\n",
            "\n",
            "=============== Epoch: 35\n",
            "train batch [40/41]: loss 0.006331234704703093\n",
            "val batch [3/4]: loss 0.0075362324714660645\n",
            "test batch [4/5]: loss 0.3868041932582855\n",
            "Train loss: 0.005063675616572543, Train accuracy: 0.9986579418182373\n",
            "Val loss: 2.6464878544211388, Val accuracy: 0.5\n",
            "Test loss: 2.2180342972278595, Test accuracy: 0.6394230723381042\n",
            "\n",
            "=============== Epoch: 36\n",
            "train batch [40/41]: loss 0.005146828945726156\n",
            "val batch [3/4]: loss 0.014947354793548584\n",
            "test batch [4/5]: loss 0.3839210867881775\n",
            "Train loss: 0.00475215371811717, Train accuracy: 0.9990413784980774\n",
            "Val loss: 2.7588521391153336, Val accuracy: 0.5625\n",
            "Test loss: 2.187663787603378, Test accuracy: 0.6426281929016113\n",
            "\n",
            "=============== Epoch: 37\n",
            "train batch [40/41]: loss 0.0006330211763270199\n",
            "val batch [3/4]: loss 0.028053224086761475\n",
            "test batch [4/5]: loss 0.48093292117118835\n",
            "Train loss: 0.004433522507741411, Train accuracy: 0.9992331266403198\n",
            "Val loss: 2.5303211510181427, Val accuracy: 0.5625\n",
            "Test loss: 2.2297270238399505, Test accuracy: 0.625\n",
            "\n",
            "=============== Epoch: 38\n",
            "train batch [40/41]: loss 0.007237888872623444\n",
            "val batch [3/4]: loss 0.012949526309967041\n",
            "test batch [4/5]: loss 0.4008256793022156\n",
            "Train loss: 0.004330111758374586, Train accuracy: 0.9996165633201599\n",
            "Val loss: 2.585347481071949, Val accuracy: 0.5\n",
            "Test loss: 2.256516528129578, Test accuracy: 0.6362179517745972\n",
            "\n",
            "=============== Epoch: 39\n",
            "train batch [40/41]: loss 0.00629660626873374\n",
            "val batch [3/4]: loss 0.009304285049438477\n",
            "test batch [4/5]: loss 0.42140689492225647\n",
            "Train loss: 0.003498869834513199, Train accuracy: 0.9996165633201599\n",
            "Val loss: 2.6812674552202225, Val accuracy: 0.5625\n",
            "Test loss: 2.2727981865406037, Test accuracy: 0.6330128312110901\n",
            "\n",
            "=============== Epoch: 40\n",
            "train batch [40/41]: loss 0.0009350553154945374\n",
            "val batch [3/4]: loss 0.014535903930664062\n",
            "test batch [4/5]: loss 0.4289872944355011\n",
            "Train loss: 0.0034687433777967603, Train accuracy: 0.9992331266403198\n",
            "Val loss: 2.7659938633441925, Val accuracy: 0.5625\n",
            "Test loss: 2.2499939262866975, Test accuracy: 0.629807710647583\n",
            "\n",
            "=============== Epoch: 41\n",
            "train batch [40/41]: loss 0.007181717548519373\n",
            "val batch [3/4]: loss 0.04248076677322388\n",
            "test batch [4/5]: loss 0.4179084300994873\n",
            "Train loss: 0.003289250066367591, Train accuracy: 0.9996165633201599\n",
            "Val loss: 2.732855014503002, Val accuracy: 0.5625\n",
            "Test loss: 2.2931105375289915, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 42\n",
            "train batch [40/41]: loss 0.0009258936042897403\n",
            "val batch [3/4]: loss 0.012965649366378784\n",
            "test batch [4/5]: loss 0.45690008997917175\n",
            "Train loss: 0.0024226809689979548, Train accuracy: 1.0\n",
            "Val loss: 2.6479956060647964, Val accuracy: 0.5625\n",
            "Test loss: 2.2845003426074983, Test accuracy: 0.6314102411270142\n",
            "\n",
            "=============== Epoch: 43\n",
            "train batch [40/41]: loss 0.0007803465123288333\n",
            "val batch [3/4]: loss 0.03136524558067322\n",
            "test batch [4/5]: loss 0.48264947533607483\n",
            "Train loss: 0.0027377093537347165, Train accuracy: 0.9996165633201599\n",
            "Val loss: 2.6791502088308334, Val accuracy: 0.5625\n",
            "Test loss: 2.275885361433029, Test accuracy: 0.6314102411270142\n",
            "\n",
            "=============== Epoch: 44\n",
            "train batch [40/41]: loss 0.004006020724773407\n",
            "val batch [3/4]: loss 0.012478530406951904\n",
            "test batch [4/5]: loss 0.4502775967121124\n",
            "Train loss: 0.003240001677512759, Train accuracy: 0.9998082518577576\n",
            "Val loss: 2.679419957101345, Val accuracy: 0.5625\n",
            "Test loss: 2.2774545013904572, Test accuracy: 0.629807710647583\n",
            "\n",
            "=============== Epoch: 45\n",
            "train batch [40/41]: loss 0.00825647171586752\n",
            "val batch [3/4]: loss 0.01002928614616394\n",
            "test batch [4/5]: loss 0.48305678367614746\n",
            "Train loss: 0.0032883562692781775, Train accuracy: 0.9998082518577576\n",
            "Val loss: 2.7665792405605316, Val accuracy: 0.5625\n",
            "Test loss: 2.3348822951316834, Test accuracy: 0.6282051205635071\n",
            "\n",
            "=============== Epoch: 46\n",
            "train batch [40/41]: loss 0.0066517796367406845\n",
            "val batch [3/4]: loss 0.00914144515991211\n",
            "test batch [4/5]: loss 0.4794105589389801\n",
            "Train loss: 0.0026044039759875797, Train accuracy: 0.9998082518577576\n",
            "Val loss: 2.722631588578224, Val accuracy: 0.5625\n",
            "Test loss: 2.3335518538951874, Test accuracy: 0.6378205418586731\n",
            "\n",
            "=============== Epoch: 47\n",
            "train batch [40/41]: loss 0.0024918902199715376\n",
            "val batch [3/4]: loss 0.011363983154296875\n",
            "test batch [4/5]: loss 0.4553706645965576\n",
            "Train loss: 0.003337988363033751, Train accuracy: 0.9996165633201599\n",
            "Val loss: 2.7287818863987923, Val accuracy: 0.5625\n",
            "Test loss: 2.3320668220520018, Test accuracy: 0.629807710647583\n",
            "\n",
            "=============== Epoch: 48\n",
            "train batch [40/41]: loss 0.0031067654490470886\n",
            "val batch [3/4]: loss 0.012891292572021484\n",
            "test batch [4/5]: loss 0.4560234248638153\n",
            "Train loss: 0.0023593463730521317, Train accuracy: 1.0\n",
            "Val loss: 2.8555976152420044, Val accuracy: 0.5625\n",
            "Test loss: 2.360841470956802, Test accuracy: 0.634615421295166\n",
            "\n",
            "=============== Epoch: 49\n",
            "train batch [40/41]: loss 0.0005741019849665463\n",
            "val batch [3/4]: loss 0.009744524955749512\n",
            "test batch [4/5]: loss 0.41812390089035034\n",
            "Train loss: 0.004312711252501552, Train accuracy: 0.9988496899604797\n",
            "Val loss: 2.834201842546463, Val accuracy: 0.5625\n",
            "Test loss: 2.3142958700656893, Test accuracy: 0.634615421295166\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78IkqIEdlNwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}