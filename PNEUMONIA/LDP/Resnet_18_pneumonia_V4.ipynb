{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Resnet_18_pneumonia_V4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxejS4BhtfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "94c63d1d-f7f6-42b4-a8c1-4775103ecd38"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 13 06:59:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqzKNkpfXrM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1443d81a-38d3-415b-d7b9-5ca06cee7be8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tkHSteTnOUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import numpy as np \n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "import copy\n",
        "from tqdm import tqdm as tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "best_model = None\n",
        "best_loss = 0.\n",
        "best_test_loss = 0.\n",
        "best_test_acc = 0.\n",
        "best_pred_labels = []\n",
        "true_labels = []\n",
        "\n",
        "pred_labels = []\n",
        "test_acc = 0.\n",
        "test_loss = 0.\n",
        "\n",
        "# device = torch.device('cuda:0')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjX3GQUHnOUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "601d4287-1ee3-4a23-af55-5c2d7beaf1f8"
      },
      "source": [
        "# train class samples from Non DP data\n",
        "print('Normal Samples in Training Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/train/NORMAL | wc -l\n",
        "print('Pneumonia Samples in Training Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/train/PNEUMONIA | wc -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Samples in Training Data\n",
            "1342\n",
            "Pneumonia Samples in Training Data\n",
            "3876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOR0OlpIbDFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6741bd62-86d5-4dc5-c90a-21b242b8250a"
      },
      "source": [
        "# Validation samples from Non DP data\n",
        "print('Normal Samples in Validation Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/val/NORMAL | wc -l\n",
        "print('Pneumonia Samples in Validation Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/val/PNEUMONIA | wc -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Samples in Validation Data\n",
            "9\n",
            "Pneumonia Samples in Validation Data\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8YxWrN7nOUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4acc0d3e-51c0-472e-dee2-5525c9b69fda"
      },
      "source": [
        "# Testing samples from Non DP data\n",
        "print('Normal Samples in Testing Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/test/NORMAL | wc -l\n",
        "print('Pneumonia Samples in Testing Data')\n",
        "!ls -l /content/drive/\"My Drive\"/NDP_Data/chest_xray/test/PNEUMONIA | wc -l"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Samples in Testing Data\n",
            "235\n",
            "Pneumonia Samples in Testing Data\n",
            "391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiuaHzKIFjYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copying to local to process/train faster\n",
        "\n",
        "!cp -R /content/drive/\"My Drive\"/NDP_Data/chest_xray/train ./\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GZsr5LpFtXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copying to local to process/run faster during validation inference\n",
        "\n",
        "!cp -R /content/drive/\"My Drive\"/NDP_Data/chest_xray/val ./\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh3E7LaXFukl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copying to local to process/run faster during testing inference\n",
        "\n",
        "!cp -R /content/drive/\"My Drive\"/NDP_Data/chest_xray/test ./"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfTrqSj1JSCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2aa3b4b8-c668-4d2c-ef08-677aaade75e2"
      },
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 87468\n",
            "drwxr-xr-x 1 root root     4096 Jun 26 16:26 sample_data\n",
            "drwx------ 4 root root     4096 Jul 13 05:18 train\n",
            "drwx------ 4 root root     4096 Jul 13 05:42 val\n",
            "drwx------ 4 root root     4096 Jul 13 05:44 test\n",
            "-rw-r--r-- 1 root root 44769414 Jul 13 06:51 resnet34-chest-x-ray_ldp-best-42.pt\n",
            "-rw-r--r-- 1 root root 44769420 Jul 13 06:57 resnet34-chest-x-ray-42.pt\n",
            "drwx------ 4 root root     4096 Jul 13 06:59 drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP4UeXeyoTgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "47c4f15b-9d2f-44f0-f880-f41c23789617"
      },
      "source": [
        "!ls -l ./train/NORMAL | wc -l\n",
        "!ls -l ./train/PNEUMONIA | wc -l\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1342\n",
            "3876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoKGl1gFoTjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb3b443d-6e69-4823-9090-20a0da28c3d7"
      },
      "source": [
        "!ls -l ./val/NORMAL | wc -l\n",
        "!ls -l ./val/PNEUMONIA | wc -l"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Pc3iSF5SIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3fa53778-4472-4f94-c4c1-57c568e8c0d5"
      },
      "source": [
        "!ls -l ./test/NORMAL | wc -l\n",
        "!ls -l ./test/PNEUMONIA | wc -l"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235\n",
            "391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jx5gkIc5SLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPDTSXKWnOUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ChestXRay(torchvision.datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        sample, target = super().__getitem__(index)\n",
        "        path, _ = self.samples[index]\n",
        "        \n",
        "        target = 0\n",
        "        if 'PNEUMONIA' in path:\n",
        "            target = 1\n",
        "        \n",
        "        return sample, target\n",
        "       "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-_xESJtnOU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.RandomAffine(0, translate=(0, 0.1), scale=(1, 1.10)),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "#train_dataset = ChestXRay('/content/drive/My Drive/NDP_Data/chest_xray/train/', transform=train_transforms)\n",
        "#val_dataset = ChestXRay('/content/drive/My Drive/NDP_Data/chest_xray/val/', transform=train_transforms)\n",
        "#test_dataset = ChestXRay('/content/drive/My Drive/NDP_Data/chest_xray/test/', transform=transforms)\n",
        "\n",
        "train_dataset = ChestXRay('./train/', transform=train_transforms)\n",
        "val_dataset = ChestXRay('./val/', transform=train_transforms)\n",
        "test_dataset = ChestXRay('./test/', transform=transforms)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPtm7Zaruoqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee19YDP1nOVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2b1cf8d-5edf-4fa1-98b1-7f3b2746f1fe"
      },
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = torch.nn.Linear(in_features=512, out_features=2)\n",
        "\n",
        "model = model.to(device)\n",
        "model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61IVJvrmr7th",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "815aacfd-1df3-4d73-c1dd-dc75bbda1bfd"
      },
      "source": [
        "summary(model.cuda(), [(3,224,224,)])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 11,177,538\n",
            "Trainable params: 11,177,538\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhXhlzFK2Dl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5U-QpQHr7wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAoD68pMf5oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epoch(model, dataloader, criterion, optimizer, lr_scheduler, phase='train'):\n",
        "    epoch_loss = 0.\n",
        "    epoch_acc = 0.\n",
        "    \n",
        "    batch_num = 0.\n",
        "    samples_num = 0.\n",
        "    \n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    \n",
        "    for batch_idx, (data, labels) in enumerate(dataloader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "            outputs = model(data)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "        \n",
        "        true_labels.append(labels.detach().cpu())\n",
        "        pred_labels.append(preds.detach().cpu())\n",
        "        \n",
        "        if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        print(f'\\r{phase} batch [{batch_idx}/{len(dataloader)}]: loss {loss.item()}', end='', flush=True)\n",
        "        epoch_loss += loss.detach().cpu().item()\n",
        "        epoch_acc += torch.sum(preds == labels.data)\n",
        "        batch_num += 1\n",
        "        samples_num += len(labels)\n",
        "    \n",
        "    print()\n",
        "    return epoch_loss / batch_num, epoch_acc / samples_num, torch.cat(true_labels).numpy(), torch.cat(pred_labels).numpy()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68w_Ljsff9wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7qXbQPUgRnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCUrp4S-gRqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=0.001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAn4FWp3nOVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b065874-ba44-40fb-fa92-4155ba1f1176"
      },
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "test_losses = []\n",
        "output_folder = '/content/drive/My Drive/Dataset/a/'\n",
        "for epoch in range(50):\n",
        "    print('='*15, f'Epoch: {epoch}')\n",
        "    \n",
        "    train_loss, train_acc, _, _ = run_epoch(model, train_dataloader, criterion, optimizer, lr_scheduler)\n",
        "    val_loss, val_acc, _, _ = run_epoch(model, val_dataloader, criterion, optimizer, lr_scheduler, phase='val')\n",
        "    test_loss, test_acc, true_labels, pred_labels = run_epoch(model, test_dataloader, criterion, optimizer, lr_scheduler, phase='test')\n",
        "    \n",
        "    print(f'Train loss: {train_loss}, Train accuracy: {train_acc}')\n",
        "    print(f'Val loss: {val_loss}, Val accuracy: {val_acc}')\n",
        "    print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n",
        "    print()\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    \n",
        "    np.save(output_folder+'/train_losses',train_losses)\n",
        "    np.save(output_folder+'/val_losses',val_losses)\n",
        "    np.save(output_folder+'/test_losses',test_losses)\n",
        "    \n",
        "    torch.save({'epoch': epoch, 'model': model.state_dict()}, f'resnet34-chest-x-ray-{seed}.pt')\n",
        "    \n",
        "    if best_model is None or val_loss < best_loss:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_loss = val_loss\n",
        "        best_test_loss = test_loss\n",
        "        best_test_acc = test_acc \n",
        "        best_pred_labels = pred_labels\n",
        "        torch.save({'epoch': epoch, 'model': model.state_dict()}, f'resnet34-chest-x-ray_ldp-best-{seed}.pt')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=============== Epoch: 0\n",
            "train batch [40/41]: loss 0.2185022383928299\n",
            "val batch [3/4]: loss 0.11388425529003143\n",
            "test batch [4/5]: loss 0.0927753821015358\n",
            "Train loss: 0.24104591495380168, Train accuracy: 0.9018404483795166\n",
            "Val loss: 0.5357109718024731, Val accuracy: 0.625\n",
            "Test loss: 0.31377714723348615, Test accuracy: 0.8669871687889099\n",
            "\n",
            "=============== Epoch: 1\n",
            "train batch [40/41]: loss 0.0517340749502182\n",
            "val batch [3/4]: loss 0.03946506977081299\n",
            "test batch [4/5]: loss 0.04185178130865097\n",
            "Train loss: 0.1185072021695172, Train accuracy: 0.9545628428459167\n",
            "Val loss: 0.7500612512230873, Val accuracy: 0.625\n",
            "Test loss: 0.3593676585704088, Test accuracy: 0.8573718070983887\n",
            "\n",
            "=============== Epoch: 2\n",
            "train batch [40/41]: loss 0.08979824930429459\n",
            "val batch [3/4]: loss 0.027016282081604004\n",
            "test batch [4/5]: loss 0.041576892137527466\n",
            "Train loss: 0.08583011814370388, Train accuracy: 0.9664493799209595\n",
            "Val loss: 0.5160141214728355, Val accuracy: 0.6875\n",
            "Test loss: 0.306098460406065, Test accuracy: 0.8942307829856873\n",
            "\n",
            "=============== Epoch: 3\n",
            "train batch [40/41]: loss 0.14116407930850983\n",
            "val batch [3/4]: loss 0.008713960647583008\n",
            "test batch [4/5]: loss 0.025578880682587624\n",
            "Train loss: 0.07209588278357576, Train accuracy: 0.9735429286956787\n",
            "Val loss: 0.5017342269420624, Val accuracy: 0.8125\n",
            "Test loss: 0.33689587414264677, Test accuracy: 0.875\n",
            "\n",
            "=============== Epoch: 4\n",
            "train batch [40/41]: loss 0.062382351607084274\n",
            "val batch [3/4]: loss 0.003127157688140869\n",
            "test batch [4/5]: loss 0.012142470106482506\n",
            "Train loss: 0.05797992296880338, Train accuracy: 0.9796779155731201\n",
            "Val loss: 0.9172366224229336, Val accuracy: 0.625\n",
            "Test loss: 0.40859341751784084, Test accuracy: 0.8637820482254028\n",
            "\n",
            "=============== Epoch: 5\n",
            "train batch [40/41]: loss 0.0841146931052208\n",
            "val batch [3/4]: loss 0.045331478118896484\n",
            "test batch [4/5]: loss 0.046509284526109695\n",
            "Train loss: 0.05212578318286233, Train accuracy: 0.981019914150238\n",
            "Val loss: 0.21128299832344055, Val accuracy: 0.875\n",
            "Test loss: 0.24390020370483398, Test accuracy: 0.9102564454078674\n",
            "\n",
            "=============== Epoch: 6\n",
            "train batch [40/41]: loss 0.021419644355773926\n",
            "val batch [3/4]: loss 0.004392445087432861\n",
            "test batch [4/5]: loss 0.010699051432311535\n",
            "Train loss: 0.044329716574128084, Train accuracy: 0.9850459694862366\n",
            "Val loss: 0.5288918539881706, Val accuracy: 0.625\n",
            "Test loss: 0.37860416593030094, Test accuracy: 0.8782051205635071\n",
            "\n",
            "=============== Epoch: 7\n",
            "train batch [40/41]: loss 0.04346919059753418\n",
            "val batch [3/4]: loss 0.0021396279335021973\n",
            "test batch [4/5]: loss 0.008889657445251942\n",
            "Train loss: 0.040079380112995465, Train accuracy: 0.9865797162055969\n",
            "Val loss: 0.6252568438649178, Val accuracy: 0.6875\n",
            "Test loss: 0.37436365280300377, Test accuracy: 0.884615421295166\n",
            "\n",
            "=============== Epoch: 8\n",
            "train batch [40/41]: loss 0.051502879709005356\n",
            "val batch [3/4]: loss 0.005102872848510742\n",
            "test batch [4/5]: loss 0.012205739505589008\n",
            "Train loss: 0.04250893898580859, Train accuracy: 0.9856211543083191\n",
            "Val loss: 0.3751974552869797, Val accuracy: 0.6875\n",
            "Test loss: 0.3400229873135686, Test accuracy: 0.8926281929016113\n",
            "\n",
            "=============== Epoch: 9\n",
            "train batch [40/41]: loss 0.051882047206163406\n",
            "val batch [3/4]: loss 0.000164031982421875\n",
            "test batch [4/5]: loss 0.0014759823679924011\n",
            "Train loss: 0.03640895205118307, Train accuracy: 0.986963152885437\n",
            "Val loss: 1.1532227993011475, Val accuracy: 0.625\n",
            "Test loss: 0.5958583356812597, Test accuracy: 0.8317307829856873\n",
            "\n",
            "=============== Epoch: 10\n",
            "train batch [40/41]: loss 0.012925566174089909\n",
            "val batch [3/4]: loss 0.0027196407318115234\n",
            "test batch [4/5]: loss 0.011638115160167217\n",
            "Train loss: 0.027301390859775426, Train accuracy: 0.9923312664031982\n",
            "Val loss: 0.7286440879106522, Val accuracy: 0.75\n",
            "Test loss: 0.362589480727911, Test accuracy: 0.8974359035491943\n",
            "\n",
            "=============== Epoch: 11\n",
            "train batch [40/41]: loss 0.02826840989291668\n",
            "val batch [3/4]: loss 0.00749891996383667\n",
            "test batch [4/5]: loss 0.008253826759755611\n",
            "Train loss: 0.02692957172488294, Train accuracy: 0.9913727045059204\n",
            "Val loss: 0.4688879996538162, Val accuracy: 0.6875\n",
            "Test loss: 0.44008259009569883, Test accuracy: 0.8733974695205688\n",
            "\n",
            "=============== Epoch: 12\n",
            "train batch [40/41]: loss 0.0055380272679030895\n",
            "val batch [3/4]: loss 0.0007075071334838867\n",
            "test batch [4/5]: loss 0.016528110951185226\n",
            "Train loss: 0.026141583385718304, Train accuracy: 0.9925229549407959\n",
            "Val loss: 0.44301169365644455, Val accuracy: 0.75\n",
            "Test loss: 0.37255904339253904, Test accuracy: 0.8974359035491943\n",
            "\n",
            "=============== Epoch: 13\n",
            "train batch [40/41]: loss 0.01690640300512314\n",
            "val batch [3/4]: loss 0.0032506585121154785\n",
            "test batch [4/5]: loss 0.01645682007074356\n",
            "Train loss: 0.02366875570903464, Train accuracy: 0.9930981397628784\n",
            "Val loss: 0.34869762510061264, Val accuracy: 0.875\n",
            "Test loss: 0.34956984091550114, Test accuracy: 0.9006410241127014\n",
            "\n",
            "=============== Epoch: 14\n",
            "train batch [40/41]: loss 0.050081927329301834\n",
            "val batch [3/4]: loss 0.0008653998374938965\n",
            "test batch [4/5]: loss 0.004425112158060074\n",
            "Train loss: 0.019901243345130507, Train accuracy: 0.9938650131225586\n",
            "Val loss: 0.2911652773618698, Val accuracy: 0.9375\n",
            "Test loss: 0.4288212828338146, Test accuracy: 0.8782051205635071\n",
            "\n",
            "=============== Epoch: 15\n",
            "train batch [40/41]: loss 0.030185053125023842\n",
            "val batch [3/4]: loss 0.001985788345336914\n",
            "test batch [4/5]: loss 0.01110347080975771\n",
            "Train loss: 0.019662153804901897, Train accuracy: 0.9946318864822388\n",
            "Val loss: 0.351331502199173, Val accuracy: 0.8125\n",
            "Test loss: 0.3930951597169042, Test accuracy: 0.8974359035491943\n",
            "\n",
            "=============== Epoch: 16\n",
            "train batch [40/41]: loss 0.0065451730042696\n",
            "val batch [3/4]: loss 0.0022484660148620605\n",
            "test batch [4/5]: loss 0.015648601576685905\n",
            "Train loss: 0.013360538940149836, Train accuracy: 0.9973159432411194\n",
            "Val loss: 0.34966040402650833, Val accuracy: 0.8125\n",
            "Test loss: 0.3636305572465062, Test accuracy: 0.9038461446762085\n",
            "\n",
            "=============== Epoch: 17\n",
            "train batch [40/41]: loss 0.032296862453222275\n",
            "val batch [3/4]: loss 0.001392662525177002\n",
            "test batch [4/5]: loss 0.009371615014970303\n",
            "Train loss: 0.0154968361801854, Train accuracy: 0.9959738850593567\n",
            "Val loss: 0.38525472581386566, Val accuracy: 0.8125\n",
            "Test loss: 0.4104323025792837, Test accuracy: 0.8942307829856873\n",
            "\n",
            "=============== Epoch: 18\n",
            "train batch [40/41]: loss 0.0093237841501832\n",
            "val batch [3/4]: loss 0.0014801025390625\n",
            "test batch [4/5]: loss 0.009750579483807087\n",
            "Train loss: 0.016492941961964457, Train accuracy: 0.995398759841919\n",
            "Val loss: 0.5761644542217255, Val accuracy: 0.8125\n",
            "Test loss: 0.4358025551773608, Test accuracy: 0.8878205418586731\n",
            "\n",
            "=============== Epoch: 19\n",
            "train batch [40/41]: loss 0.003159845946356654\n",
            "val batch [3/4]: loss 0.0003521442413330078\n",
            "test batch [4/5]: loss 0.009716039523482323\n",
            "Train loss: 0.01512605138690915, Train accuracy: 0.9963573217391968\n",
            "Val loss: 0.6826736703515053, Val accuracy: 0.75\n",
            "Test loss: 0.44244971834123137, Test accuracy: 0.8926281929016113\n",
            "\n",
            "=============== Epoch: 20\n",
            "train batch [40/41]: loss 0.02430485375225544\n",
            "val batch [3/4]: loss 0.0001628398895263672\n",
            "test batch [4/5]: loss 0.01791832409799099\n",
            "Train loss: 0.014100477315212896, Train accuracy: 0.995782196521759\n",
            "Val loss: 0.3425232768058777, Val accuracy: 0.875\n",
            "Test loss: 0.39269256629049776, Test accuracy: 0.9006410241127014\n",
            "\n",
            "=============== Epoch: 21\n",
            "train batch [40/41]: loss 0.006429258733987808\n",
            "val batch [3/4]: loss 0.0007759928703308105\n",
            "test batch [4/5]: loss 0.01812223717570305\n",
            "Train loss: 0.01131091847243469, Train accuracy: 0.997124195098877\n",
            "Val loss: 0.6413411349058151, Val accuracy: 0.75\n",
            "Test loss: 0.41811043843626977, Test accuracy: 0.8974359035491943\n",
            "\n",
            "=============== Epoch: 22\n",
            "train batch [40/41]: loss 0.018145699054002762\n",
            "val batch [3/4]: loss 0.00032317638397216797\n",
            "test batch [4/5]: loss 0.009261035360395908\n",
            "Train loss: 0.009661090537542251, Train accuracy: 0.9982745051383972\n",
            "Val loss: 0.6462079584598541, Val accuracy: 0.8125\n",
            "Test loss: 0.45322145922109486, Test accuracy: 0.8878205418586731\n",
            "\n",
            "=============== Epoch: 23\n",
            "train batch [40/41]: loss 0.006389898713678122\n",
            "val batch [3/4]: loss 0.0007733702659606934\n",
            "test batch [4/5]: loss 0.009569168090820312\n",
            "Train loss: 0.00956303926139343, Train accuracy: 0.9980828166007996\n",
            "Val loss: 0.669580951333046, Val accuracy: 0.75\n",
            "Test loss: 0.476453501638025, Test accuracy: 0.8878205418586731\n",
            "\n",
            "=============== Epoch: 24\n",
            "train batch [40/41]: loss 0.013127986341714859\n",
            "val batch [3/4]: loss 0.0002949237823486328\n",
            "test batch [4/5]: loss 0.0063026645220816135\n",
            "Train loss: 0.008324486294352427, Train accuracy: 0.9980828166007996\n",
            "Val loss: 0.5277265012264252, Val accuracy: 0.75\n",
            "Test loss: 0.440586487390101, Test accuracy: 0.8990384936332703\n",
            "\n",
            "=============== Epoch: 25\n",
            "train batch [40/41]: loss 0.0019076019525527954\n",
            "val batch [3/4]: loss 0.0012502670288085938\n",
            "test batch [4/5]: loss 0.009315873496234417\n",
            "Train loss: 0.008700737865959726, Train accuracy: 0.9976993799209595\n",
            "Val loss: 0.5899278521537781, Val accuracy: 0.8125\n",
            "Test loss: 0.4809740295633674, Test accuracy: 0.8894230723381042\n",
            "\n",
            "=============== Epoch: 26\n",
            "train batch [40/41]: loss 0.008220608346164227\n",
            "val batch [3/4]: loss 0.000387728214263916\n",
            "test batch [4/5]: loss 0.009900746867060661\n",
            "Train loss: 0.006262686739607555, Train accuracy: 0.9996165633201599\n",
            "Val loss: 0.46511802077293396, Val accuracy: 0.875\n",
            "Test loss: 0.49665205664932727, Test accuracy: 0.8942307829856873\n",
            "\n",
            "=============== Epoch: 27\n",
            "train batch [40/41]: loss 0.008495336398482323\n",
            "val batch [3/4]: loss 0.0005939006805419922\n",
            "test batch [4/5]: loss 0.010773619636893272\n",
            "Train loss: 0.007142090284061141, Train accuracy: 0.9976993799209595\n",
            "Val loss: 0.7105617821216583, Val accuracy: 0.8125\n",
            "Test loss: 0.4532946006394923, Test accuracy: 0.8990384936332703\n",
            "\n",
            "=============== Epoch: 28\n",
            "train batch [40/41]: loss 0.0036922309082001448\n",
            "val batch [3/4]: loss 3.528594970703125e-05\n",
            "test batch [4/5]: loss 0.003227127017453313\n",
            "Train loss: 0.006528706079712365, Train accuracy: 0.9984662532806396\n",
            "Val loss: 0.72311931848526, Val accuracy: 0.75\n",
            "Test loss: 0.5710588027257473, Test accuracy: 0.8766025900840759\n",
            "\n",
            "=============== Epoch: 29\n",
            "train batch [40/41]: loss 0.006695310119539499\n",
            "val batch [3/4]: loss 0.0001729726791381836\n",
            "test batch [4/5]: loss 0.011488387361168861\n",
            "Train loss: 0.005418327875526213, Train accuracy: 0.9992331266403198\n",
            "Val loss: 0.550822451710701, Val accuracy: 0.8125\n",
            "Test loss: 0.5086825806647539, Test accuracy: 0.8878205418586731\n",
            "\n",
            "=============== Epoch: 30\n",
            "train batch [40/41]: loss 0.004634704906493425\n",
            "val batch [3/4]: loss 0.0001532435417175293\n",
            "test batch [4/5]: loss 0.0096793407574296\n",
            "Train loss: 0.005776087957911375, Train accuracy: 0.9990413784980774\n",
            "Val loss: 0.5258819907903671, Val accuracy: 0.6875\n",
            "Test loss: 0.5067519860342145, Test accuracy: 0.884615421295166\n",
            "\n",
            "=============== Epoch: 31\n",
            "train batch [40/41]: loss 0.010310349054634571\n",
            "val batch [3/4]: loss 0.00018072128295898438\n",
            "test batch [4/5]: loss 0.007325468119233847\n",
            "Train loss: 0.006205423803227704, Train accuracy: 0.9988496899604797\n",
            "Val loss: 0.5254703760147095, Val accuracy: 0.75\n",
            "Test loss: 0.5416437656618655, Test accuracy: 0.8830128312110901\n",
            "\n",
            "=============== Epoch: 32\n",
            "train batch [40/41]: loss 0.0008508041501045227\n",
            "val batch [3/4]: loss 0.0003153681755065918\n",
            "test batch [4/5]: loss 0.008455338887870312\n",
            "Train loss: 0.005262814195281486, Train accuracy: 0.9990413784980774\n",
            "Val loss: 0.5852693915367126, Val accuracy: 0.8125\n",
            "Test loss: 0.5354810215532779, Test accuracy: 0.8830128312110901\n",
            "\n",
            "=============== Epoch: 33\n",
            "train batch [40/41]: loss 0.006405029445886612\n",
            "val batch [3/4]: loss 0.0001398324966430664\n",
            "test batch [4/5]: loss 0.013466885313391685\n",
            "Train loss: 0.008679873889266717, Train accuracy: 0.9976993799209595\n",
            "Val loss: 0.43157555907964706, Val accuracy: 0.8125\n",
            "Test loss: 0.4750639290548861, Test accuracy: 0.9022436141967773\n",
            "\n",
            "=============== Epoch: 34\n",
            "train batch [40/41]: loss 0.005331350490450859\n",
            "val batch [3/4]: loss 8.034706115722656e-05\n",
            "test batch [4/5]: loss 0.008443213067948818\n",
            "Train loss: 0.00663737684670018, Train accuracy: 0.9986579418182373\n",
            "Val loss: 0.40368878841400146, Val accuracy: 0.8125\n",
            "Test loss: 0.5368808998726309, Test accuracy: 0.8894230723381042\n",
            "\n",
            "=============== Epoch: 35\n",
            "train batch [40/41]: loss 0.00633148243650794\n",
            "val batch [3/4]: loss 0.00022727251052856445\n",
            "test batch [4/5]: loss 0.007927743718028069\n",
            "Train loss: 0.005553199262244672, Train accuracy: 0.9990413784980774\n",
            "Val loss: 0.5348453372716904, Val accuracy: 0.75\n",
            "Test loss: 0.5305268732830882, Test accuracy: 0.8926281929016113\n",
            "\n",
            "=============== Epoch: 36\n",
            "train batch [40/41]: loss 0.002643175423145294\n",
            "val batch [3/4]: loss 7.200241088867188e-05\n",
            "test batch [4/5]: loss 0.009854312054812908\n",
            "Train loss: 0.00413654052947716, Train accuracy: 0.9994248151779175\n",
            "Val loss: 0.4669196158647537, Val accuracy: 0.8125\n",
            "Test loss: 0.5301568179391325, Test accuracy: 0.8926281929016113\n",
            "\n",
            "=============== Epoch: 37\n",
            "train batch [40/41]: loss 0.008362328633666039\n",
            "val batch [3/4]: loss 0.0004162788391113281\n",
            "test batch [4/5]: loss 0.012271745130419731\n",
            "Train loss: 0.00511393129325858, Train accuracy: 0.9994248151779175\n",
            "Val loss: 0.6256156861782074, Val accuracy: 0.8125\n",
            "Test loss: 0.4946058434434235, Test accuracy: 0.8990384936332703\n",
            "\n",
            "=============== Epoch: 38\n",
            "train batch [40/41]: loss 0.0037448860239237547\n",
            "val batch [3/4]: loss 6.270408630371094e-05\n",
            "test batch [4/5]: loss 0.005127526819705963\n",
            "Train loss: 0.0043416660017810945, Train accuracy: 0.9992331266403198\n",
            "Val loss: 0.5522089600563049, Val accuracy: 0.8125\n",
            "Test loss: 0.5719861581921577, Test accuracy: 0.8878205418586731\n",
            "\n",
            "=============== Epoch: 39\n",
            "train batch [40/41]: loss 0.005650354083627462\n",
            "val batch [3/4]: loss 5.2094459533691406e-05\n",
            "test batch [4/5]: loss 0.0072102174162864685\n",
            "Train loss: 0.005373946283148919, Train accuracy: 0.9988496899604797\n",
            "Val loss: 0.30671365559101105, Val accuracy: 0.8125\n",
            "Test loss: 0.5230031980201602, Test accuracy: 0.8926281929016113\n",
            "\n",
            "=============== Epoch: 40\n",
            "train batch [40/41]: loss 0.005217758938670158\n",
            "val batch [3/4]: loss 8.96453857421875e-05\n",
            "test batch [4/5]: loss 0.0059457942843437195\n",
            "Train loss: 0.004552914488424615, Train accuracy: 0.9988496899604797\n",
            "Val loss: 0.635332390666008, Val accuracy: 0.75\n",
            "Test loss: 0.5347848767414689, Test accuracy: 0.8910256624221802\n",
            "\n",
            "=============== Epoch: 41\n",
            "train batch [40/41]: loss 0.007696143817156553\n",
            "val batch [3/4]: loss 0.00011968612670898438\n",
            "test batch [4/5]: loss 0.00399143248796463\n",
            "Train loss: 0.004379837171787896, Train accuracy: 0.9992331266403198\n",
            "Val loss: 0.5061010122299194, Val accuracy: 0.8125\n",
            "Test loss: 0.5531142277643084, Test accuracy: 0.8894230723381042\n",
            "\n",
            "=============== Epoch: 42\n",
            "train batch [40/41]: loss 0.001406058669090271\n",
            "val batch [3/4]: loss 0.0001386404037475586\n",
            "test batch [4/5]: loss 0.006359676364809275\n",
            "Train loss: 0.003917450073924734, Train accuracy: 0.9992331266403198\n",
            "Val loss: 0.6379410922527313, Val accuracy: 0.8125\n",
            "Test loss: 0.5398077306337654, Test accuracy: 0.8974359035491943\n",
            "\n",
            "=============== Epoch: 43\n",
            "train batch [40/41]: loss 0.002030014991760254\n",
            "val batch [3/4]: loss 5.0067901611328125e-05\n",
            "test batch [4/5]: loss 0.0034461836330592632\n",
            "Train loss: 0.003116776587486994, Train accuracy: 0.9996165633201599\n",
            "Val loss: 0.6387325823307037, Val accuracy: 0.8125\n",
            "Test loss: 0.5825632157735526, Test accuracy: 0.8862179517745972\n",
            "\n",
            "=============== Epoch: 44\n",
            "train batch [40/41]: loss 0.0012595417210832238\n",
            "val batch [3/4]: loss 0.00023561716079711914\n",
            "test batch [4/5]: loss 0.007467147894203663\n",
            "Train loss: 0.0032482716374144685, Train accuracy: 0.9998082518577576\n",
            "Val loss: 0.6121564954519272, Val accuracy: 0.8125\n",
            "Test loss: 0.5190943006426096, Test accuracy: 0.8958333730697632\n",
            "\n",
            "=============== Epoch: 45\n",
            "train batch [40/41]: loss 0.0009853256633505225\n",
            "val batch [3/4]: loss 0.00013303756713867188\n",
            "test batch [4/5]: loss 0.0038158430252224207\n",
            "Train loss: 0.003881542429486971, Train accuracy: 0.9990413784980774\n",
            "Val loss: 1.142613410949707, Val accuracy: 0.8125\n",
            "Test loss: 0.565620954753831, Test accuracy: 0.8878205418586731\n",
            "\n",
            "=============== Epoch: 46\n",
            "train batch [40/41]: loss 0.0013882803032174706\n",
            "val batch [3/4]: loss 4.076957702636719e-05\n",
            "test batch [4/5]: loss 0.0028518172912299633\n",
            "Train loss: 0.004356783567700626, Train accuracy: 0.9992331266403198\n",
            "Val loss: 0.5664324462413788, Val accuracy: 0.8125\n",
            "Test loss: 0.5806968494318425, Test accuracy: 0.8910256624221802\n",
            "\n",
            "=============== Epoch: 47\n",
            "train batch [40/41]: loss 0.0007353797554969788\n",
            "val batch [3/4]: loss 2.2530555725097656e-05\n",
            "test batch [4/5]: loss 0.0004368073132354766\n",
            "Train loss: 0.005004050675779581, Train accuracy: 0.9986579418182373\n",
            "Val loss: 0.5228458642959595, Val accuracy: 0.8125\n",
            "Test loss: 0.7391759284364525, Test accuracy: 0.8589743971824646\n",
            "\n",
            "=============== Epoch: 48\n",
            "train batch [40/41]: loss 0.0013444585492834449\n",
            "val batch [3/4]: loss 0.00010669231414794922\n",
            "test batch [4/5]: loss 0.00452395947650075\n",
            "Train loss: 0.003966024233505312, Train accuracy: 0.9990413784980774\n",
            "Val loss: 0.793153315782547, Val accuracy: 0.8125\n",
            "Test loss: 0.5566965249367058, Test accuracy: 0.884615421295166\n",
            "\n",
            "=============== Epoch: 49\n",
            "train batch [40/41]: loss 0.0019473172724246979\n",
            "val batch [3/4]: loss 0.00011086463928222656\n",
            "test batch [4/5]: loss 0.003481286345049739\n",
            "Train loss: 0.0031380609313889246, Train accuracy: 0.9994248151779175\n",
            "Val loss: 0.5564795508980751, Val accuracy: 0.8125\n",
            "Test loss: 0.553137046424672, Test accuracy: 0.8926281929016113\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78IkqIEdlNwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}